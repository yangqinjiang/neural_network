{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.neuralNetwork import neuralNetwork\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"mnist_train.csv\"\n",
    "test_filename = \"mnist_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wih=\n",
      "[[ 0.08896297  0.09424385 -0.03008408 ... -0.09779362  0.07430787\n",
      "  -0.20249009]\n",
      " [ 0.11776248 -0.05979949 -0.00562479 ...  0.04124378  0.15741998\n",
      "   0.06680674]\n",
      " [-0.0676918  -0.1460328   0.01695679 ...  0.08647841 -0.05830357\n",
      "  -0.14254763]\n",
      " ...\n",
      " [ 0.0553875  -0.12618114 -0.09101133 ...  0.06287113  0.08055182\n",
      "  -0.06522926]\n",
      " [-0.08093361  0.04062514  0.04894538 ...  0.13322406  0.10342118\n",
      "   0.14221632]\n",
      " [-0.11138935 -0.13967051  0.03978534 ...  0.06388472 -0.01973791\n",
      "  -0.09409117]]\n",
      "who=\n",
      "[[ 0.37222029  0.14049784  0.37133681 -0.42924583 -0.09175599  0.11300323\n",
      "  -0.18884649  0.32153026 -0.06404969  0.62357243 -0.58936764 -0.1694555\n",
      "  -0.04398034 -0.33268473 -0.1246031   0.65229937  0.13509395 -0.0798441\n",
      "  -0.20009743 -0.01043397  0.17569337 -0.16446516 -0.04069675 -0.00105127\n",
      "   0.3390206   0.50793469 -0.2941006   0.28652274  0.14702663 -0.11864704\n",
      "  -0.26487791 -0.05531115 -0.18300874  0.01135992  0.15703996 -0.09982856\n",
      "   0.21509211 -0.08679831 -0.0066592   0.06521653 -0.34636422 -0.25236179\n",
      "  -0.29916158 -0.15185267 -0.37338937  0.35055949 -0.18514677 -0.00129595\n",
      "  -0.72294084 -0.02587896 -0.64600032 -0.20083321 -0.37761977  0.24231931\n",
      "   0.23160407  0.09229193 -0.13023318  0.01354841 -0.18551557  0.05104517\n",
      "  -0.36589142  0.15661191  0.02930361 -0.17014986  0.14927105  0.14923572\n",
      "  -0.10081797  0.09346535 -0.34866681  0.13423214 -0.42098645  0.55437166\n",
      "   0.02194532  0.36023705 -0.3581562   0.21313317  0.19157734  0.69422966\n",
      "  -0.10116594  0.31200236 -0.02375543  0.36305631 -0.1616678  -0.34957953\n",
      "   0.24365115  0.02569079  0.16648864 -0.09560831 -0.28306096 -0.29229743\n",
      "   0.55084663 -0.10335963 -0.02220229  0.13877231 -0.38574199 -0.10021744\n",
      "   0.19176483 -0.33982363 -0.23002566  0.28646483]\n",
      " [ 0.39534612 -0.35252043  0.26384583  0.64362214  0.23463277 -0.21850178\n",
      "  -0.26860556 -0.39629384  0.08997735 -0.44585898 -0.19456965 -0.18486096\n",
      "   0.17359292  0.2053093   0.14853909  0.24419638  0.04467915  0.57532748\n",
      "   0.6956328  -0.07647909 -0.01292488 -0.13560178 -0.45858913 -0.00514541\n",
      "   0.13116594  0.0054442  -0.44941561  0.17793753  0.62952314  0.10848527\n",
      "   0.48430417 -0.4495118  -0.05662156  0.35561477 -0.39410598  0.21203814\n",
      "  -0.26881602 -0.37622887  0.03469861  0.00330962 -0.03640565  0.18093424\n",
      "   0.06045289  0.33078201  0.02084751  0.40945697 -0.02219462  0.40949312\n",
      "   0.09087403 -0.16741057 -0.07563613  0.45505285 -0.42835286 -0.12309519\n",
      "   0.22514667 -0.51060573 -0.4461728  -0.15581698  0.06382237  0.16367734\n",
      "   0.1612934  -0.25140666 -0.28362294 -0.21360197 -0.583557    0.21652589\n",
      "   0.27746136  0.14003358  0.27849869  0.31068722 -0.12513072 -0.2182966\n",
      "   0.05509641  0.87870987 -0.02332206  0.28561074  0.16464782  0.2423135\n",
      "   0.22195727  0.47503176  0.66545323  0.11397595  0.05809336  0.0073569\n",
      "   0.60218027 -0.12487145 -0.10311669  0.31278592  0.13462953  0.50357248\n",
      "  -0.0398292   0.36395794 -0.52845173  0.34129828 -0.27543251 -0.29083054\n",
      "  -0.33256334  0.21692517 -0.21607624  0.0242177 ]\n",
      " [ 0.24186009  0.07762296  0.02512998 -0.36180986  0.15681918 -0.12467622\n",
      "  -0.20608072 -0.05364603 -0.55690216 -0.37449244  0.4063051   0.17283302\n",
      "  -0.04266075 -0.13839855 -0.46935486 -0.0875651   0.22063515  0.04233696\n",
      "   0.27241134 -0.29970991  0.42533277  0.01365451  0.22664378 -0.23062845\n",
      "  -0.24009387  0.20684525 -0.1138202   0.04970443 -0.2185722   0.28891843\n",
      "   0.32894358  0.23004027 -0.46436075  0.43196142  0.16855627 -0.39024708\n",
      "   0.03640514 -0.01637796 -0.22229473 -0.77305811  0.60196164  0.12365306\n",
      "  -0.60235554  0.91196952  0.3421306  -0.21532502 -0.12464991  0.01401907\n",
      "   0.25732329  0.67515616  0.56059339  0.28669032 -0.15027912 -0.19846386\n",
      "   0.15840196  0.12206436  0.22630524  0.50467411 -0.23020302  0.03565999\n",
      "  -0.01757722 -0.76671451 -0.35787197  0.31270335 -0.15930496  0.02581726\n",
      "   0.4410621   0.0466531   0.36883527  0.39062885  0.48147588 -0.72021458\n",
      "   0.30392129 -0.09840303  0.42514942  0.08981465  0.20097726  0.02287829\n",
      "   0.40493189  0.0906467   0.58408205  0.18130264  0.73356291  0.1891298\n",
      "  -0.1020673  -0.30908221  0.32852976 -0.18439896  0.1460184  -0.49180966\n",
      "   0.33282273 -0.66527221 -0.00657177 -0.3090832  -0.3672817  -0.15229455\n",
      "   0.08886265 -0.42236816 -0.16937472  0.05921602]\n",
      " [ 0.08156733 -0.05022768 -0.03064338  0.32930677 -0.32767878  0.02299622\n",
      "   0.16028671 -0.16107975  0.24526274 -0.02514656  0.37144138  0.00918433\n",
      "  -0.45542714 -0.28082225  0.37644954 -0.35874318  0.5403547  -0.73468675\n",
      "   0.45118372 -0.25001232  0.05603554  0.63654841  0.22976019 -0.47942582\n",
      "  -0.73429833  0.1219021   0.45632763 -0.02896336 -0.6120066  -0.1110697\n",
      "   0.39619268  0.099608   -0.17246968  0.10265995  0.21594921  0.43022148\n",
      "   0.37741192 -0.6113183  -0.24657168  0.04742321 -0.36495465 -0.34309661\n",
      "   0.15718597 -0.07430448  0.10842507  0.41560425  0.63569297  0.06260504\n",
      "   0.16664777  0.01984601  0.19179744 -0.00249858 -0.33214297 -0.01721211\n",
      "  -0.01827566  0.63840352  0.4142375   0.49991192  0.23910013 -0.45122096\n",
      "   0.17167908 -0.45034703 -0.02386617 -0.61462558 -0.6638626  -0.64234792\n",
      "   0.4733838  -0.17087203  0.61229444 -0.16674987 -0.10220302 -0.19889598\n",
      "  -0.31876762  0.34252615  0.06811442 -0.16823275 -0.52179927  0.23652722\n",
      "   0.48697267  0.0911259   0.26684809 -0.16112582 -0.40452934 -0.18245517\n",
      "  -0.04535055 -0.04814629 -0.4254215  -0.05056009 -0.37498021 -0.10430201\n",
      "  -0.1461901  -0.36338331  0.25375155  0.06217313  0.29909482  0.37661603\n",
      "   0.10214467 -0.28653262 -0.40102419 -0.03735515]\n",
      " [-0.26796047  0.12400662  0.21695955 -0.83933967  0.23019513  0.65307566\n",
      "   0.35883447 -0.24633499  0.04581694 -0.29562923  0.53348754  0.13760283\n",
      "  -0.04519607  0.08842284 -0.0707326  -0.20772829  0.42523139  0.32329659\n",
      "  -0.02858557 -0.13242497  0.47183225 -0.01430881 -0.66245065  0.20446917\n",
      "  -0.59306596  0.75686123  0.38920733  0.27296352 -0.26676132  0.14896138\n",
      "  -0.74369525  0.30618141 -0.22440439  0.5402858  -0.13310555 -0.02809485\n",
      "  -0.09941502 -0.23212782  0.09403741 -0.10274133 -0.0903241  -0.26413237\n",
      "  -0.11319832 -0.08149457  0.32359592 -0.17144741 -0.05578976 -0.37568308\n",
      "   0.52252457 -0.22360112  0.30791563 -0.48139032 -0.03629569 -0.35059161\n",
      "   0.40268643  0.27845425  0.37137936 -0.58678458  0.46902722 -0.14704299\n",
      "   0.47039796  0.09542844 -0.5186832  -0.14015356 -0.22931815  0.0578729\n",
      "   0.35147091 -0.1876484   0.6030444  -0.02714951  0.22492173 -0.16972757\n",
      "  -0.18801576  0.36714987  0.18140342 -0.37450403 -0.24249086 -0.12822236\n",
      "   0.08297549 -0.08263933  0.08271582  0.21010899 -0.3623999  -0.14905009\n",
      "   0.46908294  0.11059502 -0.5390106  -0.27993876  0.2014575   0.25679493\n",
      "   0.22919369 -0.44290579 -0.27238241 -0.37044081  0.62491231 -0.11682475\n",
      "  -0.03687096  0.28768922 -0.00878205 -0.46668744]\n",
      " [ 0.12754227 -0.45283383  0.12056069 -0.12610419 -0.37897125  0.15777354\n",
      "   0.17957679  0.15067391 -0.20986848 -0.1527942  -0.32081358  0.37278479\n",
      "   0.02120522 -0.09809901 -0.2345481   0.53808628  0.19006026 -0.13502791\n",
      "   0.17257463 -0.06857168 -0.23525141 -0.35804021 -0.36583428  0.20147563\n",
      "  -0.73032967 -0.22315321 -0.06553668  0.12167859 -0.21790486  0.22514106\n",
      "   0.46934579 -0.1056918   0.13985387  0.0052992   0.28638648  0.39104328\n",
      "   0.06989126  0.09783054 -0.0116066  -0.02181402 -0.02813484 -0.25429943\n",
      "  -0.43557707  0.72122207  0.15408462  0.46941133 -0.30237637 -0.190099\n",
      "   0.09842994  0.20086002  0.59872403 -0.35921584 -0.05114245  0.1469563\n",
      "  -0.12081374 -0.28471041 -0.26531527 -0.03968184  0.31297052  0.3657174\n",
      "  -0.11304042 -0.06875528  0.20315971  0.34575826  0.23997721  0.07388596\n",
      "  -0.28765258 -0.19838845 -0.02300284 -0.56005241 -0.4577204  -0.31274528\n",
      "  -0.24464081  0.02293119 -0.05301381 -0.39621626  0.07584562 -0.61725381\n",
      "   0.5495524  -0.4158787   0.35911788 -0.16186485  0.20194076 -0.5361852\n",
      "  -0.38281054  0.10662119 -0.22309892 -0.22353422 -0.79144133  0.34817928\n",
      "   0.40634078  0.52638692  0.27495503  0.25561037  0.13548629 -0.15597599\n",
      "  -0.36699617  0.05101453  0.25162514 -0.17762518]\n",
      " [ 0.41936804 -0.64125364  0.15048127  0.23543276  0.29001512 -0.43958771\n",
      "  -0.33543829 -0.39098381 -0.08152236  0.14914361 -0.14864535 -0.22576214\n",
      "  -0.86557081  0.55889885  0.19467964 -0.17782273 -0.18577715  0.11556124\n",
      "  -0.17890843  0.30042243  0.13002313  0.30401048 -0.45771791  0.39779125\n",
      "  -0.26748986 -0.05273509  0.47293242 -0.34041382 -0.3009542   0.2681838\n",
      "  -0.43191461 -0.26848421  0.26623741  0.59760089 -0.15040978 -0.19252245\n",
      "   0.08530524 -0.24476886  0.12495934  0.01277756 -0.00941147  0.2903707\n",
      "  -0.29754429  0.38522521  0.08235241 -0.47918266 -0.14249127  0.02450013\n",
      "   0.04315721  0.35275163  0.21913182 -0.77835861  0.1476278  -0.07412354\n",
      "  -0.2458141  -0.05021474  0.03753611 -0.15307819  0.55360497 -0.12966194\n",
      "   0.64363136 -0.51515126  0.17069507  0.09356461  0.00917563 -0.36505459\n",
      "   0.29098767  0.21648233  0.02827794 -0.28903965  0.32773011  0.04311564\n",
      "   0.08985628  0.1626645   0.16539356  0.03405453  0.33414078 -0.22969543\n",
      "  -0.38053619  0.21557439 -0.5969237  -0.30627797  0.37610286 -0.3315197\n",
      "  -0.16074812  0.31324517 -0.28965737 -0.09836447  0.22569766 -0.11696388\n",
      "   0.28656562 -0.31283899  0.38367231 -0.32401914 -0.0590652   0.20390963\n",
      "   0.46683749 -0.05198125  0.38357698 -0.36128525]\n",
      " [ 0.06854683  0.44261222 -0.07960737 -0.54011859 -0.1490437  -0.04863018\n",
      "   0.05565047  0.42316002  0.1668485   0.32190973 -0.00448504 -0.33256196\n",
      "   0.27539756  0.11719989  0.0100855  -0.17723758 -0.61997316 -0.1508319\n",
      "   0.0503992   0.07606033  0.27246162 -0.06925981  0.05086661 -0.22117444\n",
      "  -0.02203569  0.24528202 -0.03446689 -0.63646175 -0.54567399  0.17158493\n",
      "   0.08692556 -0.20568234 -0.13981813  0.06699088  0.12134092 -0.43351803\n",
      "  -0.15252073  0.02110014 -0.17726941  0.18354729 -0.0378825   0.3446575\n",
      "   0.27154772  0.04202284 -0.07351371 -0.41357689 -0.0727141   0.10915244\n",
      "   0.1108632   0.06555591  0.1152751   0.10465602  0.17355108  0.44210091\n",
      "   0.54328175  0.49887045 -0.38876279 -0.51496236 -0.36230095  0.13616902\n",
      "  -0.28054697 -0.39680712  0.66894543  0.53435455  0.01837602  0.17084868\n",
      "   0.03786085 -0.13998849  0.01860024 -0.11495746  0.01073852 -0.26169398\n",
      "  -0.18522305  0.56684946 -0.34669171  0.25878212  0.26062151 -0.32172389\n",
      "  -0.02587382 -0.15817569 -0.12138689 -0.06261645 -0.02034411  0.05425683\n",
      "   0.03006694  0.18486531 -0.07272563 -0.48038419 -0.3732753  -0.29829477\n",
      "  -0.45117983  0.05573554  0.25929964 -0.23852227  0.32857122  0.11224716\n",
      "  -0.12117183 -0.50876684  0.14413666 -0.00303199]\n",
      " [-0.22535836 -0.00402162  0.03190206  0.21383115 -0.06598304  0.03932627\n",
      "   0.25863786  0.1719275   0.21581213 -0.42135012 -0.02938716 -0.05648398\n",
      "  -0.02599088 -0.24351604 -0.07635011  0.24193062  0.07631644  0.0943271\n",
      "  -0.24218103  0.02435531 -0.40321311  0.00595559  0.13649603 -0.06029938\n",
      "   0.14991352 -0.09125143 -0.17017971  0.54710578  0.44944662 -0.32956468\n",
      "   0.45991178 -0.45456955  0.23229972  0.84782911  0.07797776  0.04305858\n",
      "  -0.37054042 -0.14060581  0.08824152  0.03396927  0.0079154  -0.2158877\n",
      "  -0.21358104  0.25620791  0.24863941 -0.31795254 -0.05005422 -0.50367084\n",
      "   0.37058861 -0.09301624  0.14695296 -0.32930627 -0.47363461 -0.09212585\n",
      "   0.43236063  0.32526511  0.33930797 -0.45702569  0.40481494 -0.45508239\n",
      "  -0.03111625  0.24884769 -0.26042474 -0.05910897 -0.15424579 -0.07034483\n",
      "  -0.25443935  0.40777337 -0.34402803 -0.12469805  0.09893376  0.01586961\n",
      "   0.06733326 -0.44735867 -0.3430237   0.02747464 -0.41474949 -0.31652852\n",
      "  -0.06904275 -0.07041886 -0.38978987 -0.08150909  0.03310501  0.00787348\n",
      "   0.15560836 -0.28113507 -0.18807871  0.26625485 -0.62168563 -0.26806645\n",
      "   0.81680818 -0.20704553  0.21504552  0.03372591  0.10488429 -0.08711573\n",
      "   0.06398738 -0.10512486 -0.15011869 -0.06857081]\n",
      " [-0.06493849 -0.09373799 -0.21309575  0.36369377  0.05500795  0.07859477\n",
      "   0.71068285  0.19915911 -0.00172773 -0.16147894 -0.01187946  0.15428141\n",
      "   0.05754139  0.0496587  -0.09238208 -0.04185493 -0.25682807  0.03259215\n",
      "   0.17516923 -0.11635043  0.14915129  0.37859149 -0.31739337  0.3699601\n",
      "   0.18726605 -0.18789541 -0.01174442  0.05956334 -0.163581    0.02496227\n",
      "  -0.02386897 -0.17645386  0.14166404 -0.05424112  0.13432591  0.03856934\n",
      "  -0.0841984  -0.43614494  0.08120594 -0.09814337  0.12555128  0.34671315\n",
      "  -0.75865075 -0.08880877 -0.23663783  0.37595154 -0.23353285 -0.14010675\n",
      "  -0.3890904  -0.20514735 -0.3109963   0.68162666 -0.02847367 -0.29147856\n",
      "   0.15378514 -0.21370404  0.298       0.56996728 -0.135274   -0.15514458\n",
      "   0.05020936  0.28518723  0.09308357 -0.21864642 -0.44321161  0.5920809\n",
      "   0.00252661  0.31438051  0.44250583 -0.57047463  0.17869264  0.40725548\n",
      "  -0.09011421 -0.05723714  0.62209214 -0.4551645   0.13907908 -0.14416564\n",
      "  -0.02771637 -0.28897617  0.2185863   0.09192774  0.74350511  0.45395877\n",
      "  -0.35494064 -0.33699939 -0.04176646  0.01256327  0.45733655 -0.04518427\n",
      "  -0.61509463 -0.0780379   0.1331335   0.29071259  0.56452093 -0.24810361\n",
      "   0.20401267 -0.14636136  0.69145603  0.1397429 ]]\n"
     ]
    }
   ],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "#learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "#create instance of neural network\n",
    "n  = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the mnist training data csv file into a list\n",
    "training_data_file = open(train_filename,'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "done\n",
      "CPU times: user 34.1 s, sys: 210 ms, total: 34.3 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('start')\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "    \n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    #create the target output values (all 0.01,except the desired label which is  0.99)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs,targets)\n",
    "    pass\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnist test data csv file into a list\n",
    "test_data_file = open(test_filename,'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# get the first test record\n",
    "all_values = test_data_list[0].split(',')\n",
    "# print the label\n",
    "print(all_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x8181a1be0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot.imshow(image_array,cmap=\"Greys\",interpolation=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.58383154e-02],\n",
       "       [1.11545199e-02],\n",
       "       [1.29233408e-02],\n",
       "       [2.46832833e-03],\n",
       "       [6.43041062e-04],\n",
       "       [3.17395131e-03],\n",
       "       [1.71436026e-02],\n",
       "       [9.86082604e-01],\n",
       "       [8.78449464e-03],\n",
       "       [1.86793160e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 14.7 ms, total: 2.46 s\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test the neural network\n",
    "# scorecard for how well the network performs, initially empty \n",
    "scorecard = []\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    #print(correct_label,\"correct label\")\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    #print(label,\"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        #network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        #network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9511\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"performance = \",scorecard_array.sum() / scorecard_array.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
